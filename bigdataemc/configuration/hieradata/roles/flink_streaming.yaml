---
# Custom flink config
flink::state_backend_checkpointdir: hdfs://dsemcflink/user/flink/flink-checkpoints
flink::savepoints_state_backend_fs_dir: hdfs://dsemcflink/user/flink/flink-savepoints

# nrpe specific for flink apps
profiles::nrpe::checks:
  'check_flink_elasticsearch-user':
    ensure: present
    sudo: true
    command: /usr/lib/nagios/plugins/check_flink_containers.sh flink_elasticsearch-user prime "elasticsearch-user-prime"
  'check_flink_elasticsearch-user-fast':
    ensure: present
    sudo: true
    command: /usr/lib/nagios/plugins/check_flink_containers.sh flink_elasticsearch-user fast "elasticsearch-user-prime-fast"
  'check_flink_event-engine':
    ensure: present
    sudo: true
    command: /usr/lib/nagios/plugins/check_flink_containers.sh flink_event-engine default "event-engine"
  'check_flink_hbase':
    ensure: present
    sudo: true
    command: /usr/lib/nagios/plugins/check_flink_containers.sh flink_hbase default "HBase-Userprofile"
  'check_flink_hbase-userresponse':
    ensure: present
    sudo: true
    command: /usr/lib/nagios/plugins/check_flink_containers.sh flink_hbase-userresponse default "HBase-Userresponse"
  'check_flink_hbase-mobileresponses':
    ensure: present
    sudo: true
    command: /usr/lib/nagios/plugins/check_flink_containers.sh flink_hbase-mobileresponses default "HBase-MobileResponse"
  'check_flink_hbase-statistics_regular':
    ensure: present
    sudo: true
    command: /usr/lib/nagios/plugins/check_flink_containers.sh flink_hbase-statistics regular "HBase-Statistics"
  'check_flink_hbase-statistics_recovery':
    ensure: present
    sudo: true
    command: /usr/lib/nagios/plugins/check_flink_containers.sh flink_hbase-statistics recovery "HBase-Statistics-Recovery"
  'check_flink_interaction-planner-statistics':
    ensure: present
    sudo: true
    command: /usr/lib/nagios/plugins/check_flink_containers.sh flink_interaction-planner default "interaction-planner-statistics"
  'check_flink_locking-injection':
    ensure: present
    sudo: true
    command: /usr/lib/nagios/plugins/check_flink_containers.sh flink_locking-injection default "HBase-Locking"
  'check_flink_relateddata_hbase':
    ensure: present
    sudo: true
    command: /usr/lib/nagios/plugins/check_flink_containers.sh flink_relateddata hbase "relateddata-hbase"
  'check_flink_relateddata_elastic':
    ensure: present
    sudo: true
    command: /usr/lib/nagios/plugins/check_flink_containers.sh flink_relateddata elastic "Elastic-Relateddata"
  'check_flink_rq_writer':
    ensure: present
    sudo: true
    command: /usr/lib/nagios/plugins/check_flink_containers.sh flink_rq_writer default "rq_cassandra_writer"
  'check_flink_phone-hbase':
    ensure: present
    sudo: true
    command: /usr/lib/nagios/plugins/check_flink_containers.sh flink_phone-hbase default "phonedata-hbase"
  'check_flink_mct_processor':
    ensure: present
    sudo: true
    command: /usr/lib/nagios/plugins/check_flink_containers.sh flink_mct_processor default "mapp-connect-processor"
  'check_flink_dmp':
    ensure: present
    sudo: true
    command: /usr/lib/nagios/plugins/check_flink_containers.sh flink_dmp default "dmp-events"
  'check_yarn_resourcemanager':
    ensure: present
    command: /usr/lib/nagios/plugins/check_procs -c 1:1 -C java -a yarn-resourcemanager
  'check_flink_kafka-reloader':
    ensure: present
    sudo: true
    command: /usr/lib/nagios/plugins/check_flink_containers.sh flink_kafka-reloader default "flink_kafka-reloader"
  'check_flink_webtrekk-segment':
    ensure: present
    sudo: true
    command: /usr/lib/nagios/plugins/check_flink_containers.sh flink_webtrekk-segment default "webtrekk-segment"
  'check_flink_product-catalog':
    ensure: present
    sudo: true
    command: /usr/lib/nagios/plugins/check_flink_containers.sh flink_hbase-product-catalog default "HBase-Productcatalog"

# flink packages
flink::packages:
  flink:
    ensure: '1.6.4-1'
  flink-metrics-libs:
    ensure: '0.0.4'

# flink applications
flink::applications::type: 'streaming'
flink::applications::defaults:
  checkpointing_interval: 10000
  checkpointing_mode: 'EXACTLY_ONCE'
  checkpointing_pause: 60000
  checkpointing_timeout: 1200000
  ds_schema_registry_path: '/services/registry'
  elasticsearch_nodes: "%{alias('es::nodes')}"
  elasticsearch_http_port: "%{hiera('es::http_port')}"
  flink_time_window_ms: 1000
  hbase_znode: "%{hiera('common_apps_settings.hbase.znode')}"
  kafka_nodes: "%{alias('kafka::brokers')}"
  kafka_broker_port: "%{hiera('kafka::broker_port')}"
  zookeeper_quorum: "%{alias('zookeeper::quorumsrv.hadoop')}"
  zookeeper_port: "%{hiera('zookeeper::ports.hadoop.clientport')}"
  services_znodes:
    userresponseevent: '/services/userresponseevent'
flink::applications::list:
  event-engine:
    package: 'event-engine-flink'
    version: '0.3.22'
    configfiles:
      '/opt/event-engine-flink/conf/config.yml':
        checkpointing.interval: "%{hiera('flink::applications::defaults.checkpointing_interval')}"
        checkpointing.pause: 180000
        collocation.DEFAULT.destination.topic: 'ee-cep-actions-emc-eu'
        collocation.DEFAULT.ignore.sysname: 'false'
        collocation.DEFAULT.name: 'EMC-EU'
        collocation.DEFAULT.url: 'https://amundsen.shortest-route.com'
        collocation.A.name: 'EMC-US'
        collocation.A.url: 'https://columbus.shortest-route.com'
        collocation.A.ignore.sysname: 'false'
        collocation.A.destination.topic: 'ee-cep-actions-emc-us'
        connection.timeout: 5000
        dmc.rule.path: '/services/dmc/eventaction/rules'
        flink.aggregate.actions.cep.parallelism: 20
        flink.aggregate.best.sendout.parallelism: 20
        flink.aggregate.event.parallelism: 20
        flink.best.sendout.time.parallelism: 20
        flink.mapping.matching.result.to.aggregable.parallelism: 20
        flink.best.sendout.time.window.ms: 60000
        flink.best.sendout.max.elements: 500
        flink.best.sendout.time.on: true
        flink.filter.invalid.event.parallelism: 20
        flink.mapping.action.to.aggregable.parallelism: 20
        flink.mapping.action.to.scheduled.parallelism: 20
        flink.mapping.matching.result.to.action.parallelism: 20
        flink.mapping.record.to.action: 20
        flink.mapping.record.to.event: 20
        flink.matching.parallelism: 20
        flink.merge.streams.parallelism: 20
        flink.sink.kafka.azkaban.parallelism: 20
        flink.sink.kafka.cep.parallelism: 20
        flink.sink.kafka.failed.events.parallelism: 20
        flink.sink.kafka.service.parallelism: 20
        flink.source.action.parallelism: 20
        flink.source.event.parallelism: 20
        flink.time.window.ms: 5000
        group.id: 'event-engine-flink-emc'
        max.elements: 100
        redis.block.when.pool.exhausted: 'true'
        redis.connection.timeout: 5000
        redis.master.port: 6380
        redis.master.url: 'event-engine-emc-lb.muc.domeus.com'
        redis.max.connections: 20
        redis.max.wait.millis: 1000
        redis.retry.count: 3
        redis.retry.interval: 500
        redis.rules.expiration.time.in.seconds: 86400
        redis.slave.port: 6381
        redis.slave.url: 'event-engine-emc-lb.muc.domeus.com'
        restart.strategy: 'fixed-delay'
        restart.strategy.fixed.delay.attempts: 10
        restart.strategy.fixed.delay.delay: '30s'
        scheduling.service.target.id: 'KAFKA_ACTIONS_ENDPOINT'
        schema.registry.path: '/schema_registry/schema_registry_master'
        secret.key: "%{alias('secrets::flink::event-engine::secret_key')}"
        socket.timeout: 15000
        topic.destination.azkaban: 'ee-azkaban-actions'
        topic.destination.failed.events: 'ee-failed-matching'
        topic.destination.scheduling.service: 'ee-scheduled-entities'
        topic.source.action: 'ee-actions'
        topic.source.event: 'ee-events'
        user.read.best.sendout.email.attribute.name: 'mlUserSendTime'
        user.read.best.sendout.time.attribute.granularity.min: 30
        user.read.config: 'client {maxRetries = 3, thriftMux = true, checkServiceAvailability = false}, processing {timeout = 3.seconds}'
  interaction-planner:
    package: 'interaction-planner-flink'
    version: '0.0.16'
    configfiles:
      '/opt/interaction-planner-flink/conf/config.yml':
        checkpointing.interval: "%{hiera('flink::applications::defaults.checkpointing_interval')}"
        collocations.DEFAULT.name: 'EMC-EU'
        collocations.DEFAULT.interactionplanner.db.username: 'iplanner_flink'
        collocations.DEFAULT.interactionplanner.db.password: "%{alias('secrets::flink::interaction-planner::default_db_password')}"
        collocations.DEFAULT.interactionplanner.db.hostname: 'dbaas-emc.muc.domeus.com'
        collocations.DEFAULT.interactionplanner.db.port: 3358
        collocations.DEFAULT.interactionplanner.db.dbname: 'interaction_planner'
        collocations.DEFAULT.interactionplanner.db.additionalConnectionParams: '?useUnicode=true&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=UTC&autoReconnect=true'
        collocations.A.name: 'EMC-US'
        collocations.A.interactionplanner.db.username: 'iplanner_flink'
        collocations.A.interactionplanner.db.password: "%{alias('secrets::flink::interaction-planner::a_db_password')}"
        collocations.A.interactionplanner.db.hostname: 'dbmql12us1c.muc.domeus.com'
        collocations.A.interactionplanner.db.port: 3306
        collocations.A.interactionplanner.db.dbname: 'iplanner_p10'
        collocations.A.interactionplanner.db.additionalConnectionParams: '?useUnicode=true&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=UTC&autoReconnect=true'
        connection.timeout: 5000
        group.id: 'interaction-planner-flink-emc'
        flink.aggregate.event.parallelism: 5
        flink.filter.invalid.event.parallelism: 5
        flink.mapping.record.to.event: 5
        flink.sink.db.interactionplanner.parallelism: 5
        flink.source.event.parallelism: 5
        flink.time.window.ms: 60000
        max.elements: 1000
        schema.registry.path: '/schema_registry/schema_registry_master'
        socket.timeout: 5000
        topic.source.event: 'interaction-planner-statistics'
  locking-injection:
    package: 'speedlayer-flink-locking-injection'
    version: '2.1.2-1'
    configfiles:
      '/opt/speedlayer-flink-locking-injection/conf/config.yml':
        auto.offset.reset: 'latest'
        checkpointing.interval: "%{hiera('flink::applications::defaults.checkpointing_interval')}"
        checkpointing.mode: "%{hiera('flink::applications::defaults.checkpointing_mode')}"
        checkpointing.pause: "%{hiera('flink::applications::defaults.checkpointing_pause')}"
        flink.sink.parallelism: 3
        flink.source.parallelism: 3
        hbase.zookeeper.znode.parent: "%{hiera('flink::applications::defaults.hbase_znode')}"
        hbase.locking.table.name: 'process'
  mobile-statistics:
    package: 'speedlayer-flink-mobile-statistics'
    version: '2.1.2-1'
    configfiles:
      '/opt/speedlayer-flink-mobile-statistics/conf/config.yml':
        auto.offset.reset: 'earliest'
        checkpointing.interval: "%{hiera('flink::applications::defaults.checkpointing_interval')}"
        checkpointing.mode: "%{hiera('flink::applications::defaults.checkpointing_mode')}"
        checkpointing.pause: "%{hiera('flink::applications::defaults.checkpointing_pause')}"
        flink.time.window.ms: "%{hiera('flink::applications::defaults.flink_time_window_ms')}"
        flink.process.parallelism: 2
        flink.sink.parallelism: 2
        flink.source.parallelism: 2
        hbase.zookeeper.znode.parent: "%{hiera('flink::applications::defaults.hbase_znode')}"
        hbase.stats.table.name: 'mobilestats-speed-0'
        hbase.stats.family.name: 'stats'
        hbase.marker.table.name: 'mobilestats-marker-0'
        hbase.marker.family.name: 'markers'
        hbase.push.stats.table.name: 'pushstats-speed-0'
        hbase.push.stats.family.name: 'stats'
        hbase.push.marker.table.name: 'pushstats-marker-0'
        hbase.push.marker.family.name: 'markers'
        hbase.zookeeper.znode.parent: "%{hiera('flink::applications::defaults.hbase_znode')}"
  relateddata-elastic:
    package: 'speedlayer-flink-relateddata-elastic'
    version: '2.1.2-1'
    configfiles:
      '/opt/speedlayer-flink-relateddata-elastic/conf/config.yml':
        group.id: test_elastic_rd
        bulk.flush.interval.ms: 1000
        bulk.flush.max.actions: 500
        hbase.auto.flush: 'true'
        checkpointing.interval: "%{hiera('flink::applications::defaults.checkpointing_interval')}"
        checkpointing.mode: "%{hiera('flink::applications::defaults.checkpointing_mode')}"
        checkpointing.timeout: 3600000
        checkpointing.pause: "%{hiera('flink::applications::defaults.checkpointing_pause')}"
        flink.time.window.ms: 200
        flink.source.parallelism: 8
        flink.process.parallelism: 32
        flink.sink.parallelism: 32
        locking.fold.parallelism: 4
        locking.sink.parallelism: 4
        auto.offset.reset: 'latest'
        locking.flush.interval.seconds: 1
        customer.blacklist: 
        index.autocreate.numberofshards: 5
        index.autocreate.numberofreplicas: 1
        index.routing.include.key: disk_type
        index.routing.include.value: ssd
        index.routing.exclude.key: disk_type
        index.routing.exclude.value: kubernetes
        elasticsearch.socket.timeout: 180000
  relateddata-hbase:
    package: 'speedlayer-flink-relateddata-hbase'
    version: '2.1.11-1'
    configfiles:
      '/opt/speedlayer-flink-relateddata-hbase/conf/config.yml':
        auto.offset.reset: 'earliest'
        checkpointing.interval: "%{hiera('flink::applications::defaults.checkpointing_interval')}"
        checkpointing.mode: "%{hiera('flink::applications::defaults.checkpointing_mode')}"
        checkpointing.pause: 0
        checkpointing.timeout: "%{hiera('flink::applications::defaults.checkpointing_timeout')}"
        flink.time.window.ms: 200
        flink.source.parallelism: 32
        flink.process.parallelism: 32
        flink.sink.parallelism: 32
        locking.fold.parallelism: 8
        locking.sink.parallelism: 8
        locking.flush.interval.seconds: 1
        hbase.zookeeper.znode.parent: "%{hiera('flink::applications::defaults.hbase_znode')}"
        hbase.table.name: 'relateddata-speed-1'
        hbase.wishlist.table.name: 'wishlist-speed-0'
        customer.whitelist.path.enable: true
        customer.whitelist.path: '/mds/snapshots/rd_whitelist.conf'
        customer.whitelist: ''
        name: 'relateddata-hbase'
      '/opt/speedlayer-flink-relateddata-hbase/conf/config_tmp.yml':
        auto.offset.reset: 'earliest'
        checkpointing.interval: "%{hiera('flink::applications::defaults.checkpointing_interval')}"
        checkpointing.mode: "%{hiera('flink::applications::defaults.checkpointing_mode')}"
        checkpointing.pause: 0
        checkpointing.timeout: "%{hiera('flink::applications::defaults.checkpointing_timeout')}"
        flink.time.window.ms: 200
        flink.process.parallelism: 8
        flink.sink.parallelism: 8
        flink.source.parallelism: 8
        hbase.zookeeper.znode.parent: "%{hiera('flink::applications::defaults.hbase_znode')}"
        hbase.table.name: 'relateddata-speed-1'
        hbase.wishlist.table.name: 'wishlist-speed-0'
        locking.enabled: false
        name: 'relateddata-hbase-tmp'
  statistics:
    package: 'speedlayer-flink-statistics'
    version: '2.0.13-1'
    configfiles:
      '/opt/speedlayer-flink-statistics/conf/config.yml':
        auto.offset.reset: 'earliest'
        checkpointing.interval: '60000'
        checkpointing.mode: "%{hiera('flink::applications::defaults.checkpointing_mode')}"
        checkpointing.pause: "%{hiera('flink::applications::defaults.checkpointing_pause')}"
        checkpointing.timeout: 1800000
        checkpointing.failOnCheckpointingErrors: 'false'
        flink.time.window.ms: "%{hiera('flink::applications::defaults.flink_time_window_ms')}"
        flink.process.stats.recovery.parallelism: 64
        flink.process.parallelism: 64
        flink.process.sync.increment.calculator.enabled: 'true'
        flink.sink.parallelism: 32
        flink.source.parallelism: 8
        flink.stats.calculation.timeout.ms: 180000
        flink.stats.calculation.threads: 100
        flink.responses.reorder.enabled: 'true'
        flink.stats.markers.message.conversions.limit: 0
        flink.stats.markers.message.limit: 0
        flink.stats.markers.results.max: 1000
        flink.stats.markers.versions: 100
        hbase.zookeeper.znode.parent: "%{hiera('flink::applications::defaults.hbase_znode')}"
        hbase.conversionstats.table.name: 'flink-statistics-conversion-0'
        hbase.marker.table.name: 'flink-statistics-marker-0'
        hbase.stats.table.name: 'flink-statistics-counters-0'
        hbase.domainstats.table.name: 'flink-statistics-domain-0'
        response.expiration.days: 2
        response.expired.path: '/tmp/userresponse-failed'
        response.assign.conversions: 'true'
        customer.whitelist:
        customer.blacklist: '552,8501,2504,12235,13000,17000,20000,8007,7121,3001,6094,5151,22264,60021'
        user.blacklist: '22280-22159514156'
        datastore.user.response.write.config: 'withCircuitBreaker = false, client { maxRetries = 3, thriftMux = true, workerThreads = 100, workerThreadPoolBufferSize = 100, checkServiceAvailability = false }, processing { timeout = 3.seconds }, recovery { fileDir = "/tmp/datastore/speedlayer-flink-statistics/minute/userResponse", period = 1.minute, threads = 50 }'
        datastore.user.response.write.recovery.config: 'withCircuitBreaker = false, client { maxRetries = 3, thriftMux = true, workerThreads = 100, workerThreadPoolBufferSize = 100, checkServiceAvailability = false }, processing { timeout = 3.seconds }, recovery { fileDir = "/tmp/datastore/speedlayer-flink-statistics/minute/recovery/userResponse", period = 1.minute, threads = 50 }'
      '/opt/speedlayer-flink-statistics/conf/config-recovery.yml':
        auto.offset.reset: 'latest'
        checkpointing.interval: '60000'
        checkpointing.mode: "%{hiera('flink::applications::defaults.checkpointing_mode')}"
        checkpointing.pause: "%{hiera('flink::applications::defaults.checkpointing_pause')}"
        checkpointing.timeout: 1800000
        checkpointing.failOnCheckpointingErrors: 'false'
        flink.time.window.ms: "%{hiera('flink::applications::defaults.flink_time_window_ms')}"
        flink.process.stats.recovery.parallelism: 32
        flink.process.parallelism: 32
        flink.process.sync.increment.calculator.enabled: 'true'
        flink.sink.parallelism: 16
        flink.source.parallelism: 4
        flink.stats.calculation.timeout.ms: 180000
        flink.stats.calculation.threads: 100
        flink.responses.reorder.enabled: 'false'
        flink.stats.markers.message.conversions.limit: 0
        flink.stats.markers.message.limit: 0
        flink.stats.markers.results.max: 1000
        flink.stats.markers.versions: 100
        hbase.zookeeper.znode.parent: "%{hiera('flink::applications::defaults.hbase_znode')}"
        hbase.conversionstats.table.name: 'flink-statistics-conversion-0'
        hbase.marker.table.name: 'flink-statistics-marker-0'
        hbase.stats.table.name: 'flink-statistics-counters-0'
        hbase.domainstats.table.name: 'flink-statistics-domain-0'
        response.expiration.days: 2
        response.expired.path: '/tmp/userresponse-failed'
        response.assign.conversions: 'true'
        customer.whitelist:
        customer.blacklist: '1,552,2504,3001,5151,6094,7121,8007,8501,12235,13000,17000,20000,22264,60021,99905,99906,99907'
        user.blacklist: '22280-22159514156'
        datastore.user.response.write.config: 'withCircuitBreaker = false, client { maxRetries = 3, thriftMux = true, workerThreads = 100, workerThreadPoolBufferSize = 100, checkServiceAvailability = false }, processing { timeout = 3.seconds }, recovery { fileDir = "/tmp/datastore/speedlayer-flink-statistics/minute/userResponse", period = 1.minute, threads = 50 }'
        datastore.user.response.write.recovery.config: 'withCircuitBreaker = false, client { maxRetries = 3, thriftMux = true, workerThreads = 100, workerThreadPoolBufferSize = 100, checkServiceAvailability = false }, processing { timeout = 3.seconds }, recovery { fileDir = "/tmp/datastore/speedlayer-flink-statistics/minute/recovery/userResponse", period = 1.minute, threads = 50 }'
  user-elastic:
    package: 'speedlayer-flink-user-elastic'
    version: '2.1.2-1'
    configfiles:
      '/opt/speedlayer-flink-user-elastic/conf/config.yml':
        name: 'elasticsearch-user-prime'
        auto.offset.reset: 'earliest'
        checkpointing.interval: "%{hiera('flink::applications::defaults.checkpointing_interval')}"
        checkpointing.mode: "%{hiera('flink::applications::defaults.checkpointing_mode')}"
        checkpointing.pause: 0
        checkpointing.timeout: 1200000
        flink.time.window.ms: 1000
        flink.source.parallelism: 20
        flink.source.membership.parallelism: 10
        flink.source.group.parallelism: 4
        flink.process.parallelism: 64
        flink.process.group.parallelism: 4
        flink.sink.parallelism: 64
        flink.flow.mobileresponse.enabled: true
        flink.source.mobileresponse.parallelism: 8
        flink.sink.mobileresponse.parallelism: 32
        flink.flow.dmpresponse.enabled: true
        flink.source.dmpresponse.parallelism: 8
        flink.sink.dmpresponse.parallelism: 32
        elasticsearch.socket.timeout: 160000
        elasticsearch.connection.timeout: 3000
        elasticsearch.sendoutquery.timeout: 45
        elasticsearch.update.retryonconflict: 5
        bulk.flush.max.actions: 500
        bulk.flush.max.size.mb: 2
        bulk.flush.interval.ms: 1000
        customer.whitelist.path: '/mds/snapshots/whitelist.conf'
        customer.whitelist.path.enable: true
        customer.blacklist: '40051,60020,60147,60148,60181,60190,60202,60205,60209,30070,30071,60215,60217,60216,60219,60221'   #P&G customers
        customer.blacklist.path.enable: false
        customer.whitelist.scope.path: '/mds/old_tenants.txt'
        customer.whitelist.scope.enable: true
        customers.sla: '99901,99902,99903,99905,99907'
        index.autocreate.refreshinverval: '10s'
        index.autocreate.numberofshards: 8
        index.autocreate.numberofreplicas: 1
        index.autocreate.translogflushsize: '512mb'
        index.autocreate.codec: 'best_compression'
        index.autocreate.nestedobjects.limit: 100000
        index.mapping.sizeEnabled: true
        index.suffix: 'prime'
        index.routing.include.key: disk_type
        index.routing.include.value: ssd
        index.routing.exclude.key: disk_type
        index.routing.exclude.value: kubernetes
        index.bigcustomer.size.threshold.gb: 100
        source.id.prefixfilter.regex: '^(USER-IMPORT-|MEMBER-IMPORT-).*'
      '/opt/speedlayer-flink-user-elastic/conf/config-fast.yml':
        name: 'elasticsearch-user-prime-fast'
        auto.offset.reset: 'earliest'
        checkpointing.interval: "%{hiera('flink::applications::defaults.checkpointing_interval')}"
        checkpointing.mode: "%{hiera('flink::applications::defaults.checkpointing_mode')}"
        checkpointing.pause: 0
        checkpointing.timeout: 1200000
        flink.time.window.ms: 1000
        flink.source.parallelism: 20
        flink.source.membership.parallelism: 10
        flink.source.group.parallelism: 4
        flink.process.parallelism: 48
        flink.process.group.parallelism: 4
        flink.sink.parallelism: 48
        flink.flow.userresponse.enabled: false
        flink.flow.mobileresponse.enabled: false
        flink.flow.dmpresponse.enabled: false
        elasticsearch.socket.timeout: 160000
        elasticsearch.connection.timeout: 3000
        elasticsearch.sendoutquery.timeout: 45
        elasticsearch.update.retryonconflict: 10
        bulk.flush.max.actions: 500
        bulk.flush.max.size.mb: 2
        bulk.flush.interval.ms: 1000
        customer.whitelist.path: '/mds/snapshots/whitelist.conf'
        customer.whitelist.path.enable: true
        customer.blacklist: '40051,60020,60147,60148,60181,60190,60202,60205,60209,30070,30071,60215,60217,60216,60219,60221'   #P&G customers
        customer.blacklist.path.enable: false
        customer.whitelist.scope.path: '/mds/old_tenants.txt'
        customer.whitelist.scope.enable: true
        customers.sla: '99901,99902,99903,99905,99907'
        index.autocreate.refreshinverval: '10s'
        index.autocreate.numberofshards: 8
        index.autocreate.numberofreplicas: 1
        index.autocreate.translogflushsize: '512mb'
        index.autocreate.codec: 'best_compression'
        index.autocreate.nestedobjects.limit: 100000
        index.mapping.sizeEnabled: true
        index.suffix: 'prime'
        index.routing.include.key: disk_type
        index.routing.include.value: ssd
        index.routing.exclude.key: disk_type
        index.routing.exclude.value: kubernetes
        index.bigcustomer.size.threshold.gb: 100
        source.id.prefixfilter.regex: '^(?!(USER-IMPORT-|MEMBER-IMPORT-).*$).*'
      '/opt/speedlayer-flink-user-elastic/conf/config-png.yml':
        name: 'elasticsearch-user-png'
        auto.offset.reset: 'earliest'
        checkpointing.interval: "%{hiera('flink::applications::defaults.checkpointing_interval')}"
        checkpointing.mode: "%{hiera('flink::applications::defaults.checkpointing_mode')}"
        checkpointing.pause: 0
        checkpointing.timeout: 1200000
        flink.time.window.ms: 1000
        flink.source.parallelism: 20
        flink.source.membership.parallelism: 10
        flink.source.group.parallelism: 4
        flink.process.parallelism: 48
        flink.process.group.parallelism: 4
        flink.sink.parallelism: 48
        flink.flow.mobileresponse.enabled: true
        flink.source.mobileresponse.parallelism: 8
        flink.sink.mobileresponse.parallelism: 32
        flink.flow.dmpresponse.enabled: true
        flink.source.dmpresponse.parallelism: 8
        flink.sink.dmpresponse.parallelism: 32
        elasticsearch.socket.timeout: 160000
        elasticsearch.connection.timeout: 3000
        elasticsearch.sendoutquery.timeout: 45
        elasticsearch.update.retryonconflict: 5
        bulk.flush.max.actions: 500
        bulk.flush.max.size.mb: 2
        bulk.flush.interval.ms: 1000
        customer.whitelist: '40051,60020,60147,60148,60181,60190,60202,60205,60209,30070,30071,60215,60217,60216,60219,60221'   #P&G customers
        customer.whitelist.path.enable: false
        customer.whitelist.scope.enable: flase
        customer.blacklist:
        customer.blacklist.path.enable: false
        index.suffix: 'prime'
      '/opt/speedlayer-flink-user-elastic/conf/config-tmp.yml':
        name: 'elasticsearch-user-tmp'
        auto.offset.reset: 'earliest'
        checkpointing.interval: 10000
        checkpointing.mode: "%{hiera('flink::applications::defaults.checkpointing_mode')}"
        checkpointing.pause: 0
        checkpointing.timeout: 1200000
        flink.time.window.ms: 1000
        flink.source.parallelism: 20
        flink.source.membership.parallelism: 10
        flink.source.group.parallelism: 4
        flink.process.parallelism: 32
        flink.process.group.parallelism: 4
        flink.sink.parallelism: 32
        flink.flow.mobileresponse.enabled: true
        flink.source.mobileresponse.parallelism: 8
        flink.sink.mobileresponse.parallelism: 32
        flink.flow.dmpresponse.enabled: true
        flink.source.dmpresponse.parallelism: 8
        flink.sink.dmpresponse.parallelism: 32
        elasticsearch.socket.timeout: 160000
        elasticsearch.connection.timeout: 3000
        elasticsearch.sendoutquery.timeout: 45
        elasticsearch.update.retryonconflict: 5
        bulk.flush.max.actions: 500
        bulk.flush.max.size.mb: 2
        bulk.flush.interval.ms: 1000
        customer.whitelist: '__TO_OVERRIDE__'
        customer.whitelist.path.enable: false
        customer.whitelist.scope.enable: false
        customer.blacklist.path.enable: false
        index.suffix: 'tmp'
        locking.enabled: false
  user-hbase:
    package: 'speedlayer-flink-user-hbase'
    version: '2.1.2-1'
    configfiles:
      '/opt/speedlayer-flink-user-hbase/conf/config.yml':
        auto.offset.reset: 'earliest'
        checkpointing.interval: "%{hiera('flink::applications::defaults.checkpointing_interval')}"
        checkpointing.mode: 'AT_LEAST_ONCE'
        checkpointing.pause: "%{hiera('flink::applications::defaults.checkpointing_pause')}"
        checkpointing.timeout: '7200000'
        flink.process.parallelism: 128
        flink.sink.parallelism: 128
        flink.source.parallelism: 40
        flink.time.window.ms: '5000'
        hbase.zookeeper.znode.parent: "%{hiera('flink::applications::defaults.hbase_znode')}"
        hbase.table.name: 'user-profile-speed-1'
        locking.flush.interval.seconds: 5
  userresponse-hbase:
    package: 'speedlayer-flink-userresponse-hbase'
    version: '2.1.4-1'
    configfiles:
      '/opt/speedlayer-flink-userresponse-hbase/conf/config.yml':
        auto.offset.reset: 'latest'
        checkpointing.interval: "%{hiera('flink::applications::defaults.checkpointing_interval')}"
        checkpointing.mode: 'EXACTLY_ONCE'
        checkpointing.pause: "%{hiera('flink::applications::defaults.checkpointing_pause')}"
        checkpointing.timeout: '1200000'
        flink.process.parallelism: 16
        flink.sink.parallelism: 16
        flink.source.parallelism: 16
        flink.time.window.ms: '1000'
        hbase.zookeeper.znode.parent: "%{hiera('flink::applications::defaults.hbase_znode')}"
        hbase.table.name: userresponse-speed-0
  response-queue-writer:
    package: 'response-queue-writer-flink'
    version: '1.0.16-1'
    configfiles:
      '/opt/response-queue-writer-flink/conf/config.yml':
        cassandra.contact.points: hp13rqcas001.muc.domeus.com,hp13rqcas002.muc.domeus.com,hp13rqcas003.muc.domeus.com
        cassandra.contact.port: 9042
        cassandra.user: cassandra
        cassandra.password: "%{alias('secrets::flink::response-queue-writer::cassandra_password')}"
        cassandra.contact.connections.local.min: 5
        cassandra.contact.connections.local.max: 12
        cassandra.contact.connections.remote.min: 6
        cassandra.contact.connections.remote.max: 15
        cassandra.contact.connect.timeout: 20000
        cassandra.contact.idle.timeout: 10000
        cassandra.contact.pool.timeout: 15000
        kafka.group.id: rq-flink-writer
        checkpointing.interval: 10000
        checkpointing.mode: EXACTLY_ONCE
        flink.time.window.ms: 500
        flink.source.parallelism: 10
        flink.process.parallelism: 10
        flink.map.parallelism: 5
        flink.sink.parallelism: 15
        flink.events.package.size: 500
        schema-registry-path: '/schema_registry/schema_registry_master'
        flow.name: rq_cassandra_writer
        flow.cassandra.keyspace: rq
        flow.cassandra.allmessages.table: all_messages
        flow.enabled: mtaresponse,linkclick,readtrack,forwardtrack,conversion,sendtransactional,smsresponse,unsubscribe,skiptracking,senttomta
        flow.mtaresponse.name: mta_response
        flow.mtaresponse.topic: rq_mta_response
        flow.mtaresponse.type: mta
        flow.mtaresponse.cassandra.table: mta_responses
        flow.linkclick.name: link_click
        flow.linkclick.topic: rq_link_click
        flow.linkclick.type: lcl
        flow.linkclick.cassandra.table: link_clicks
        flow.readtrack.name: read_track
        flow.readtrack.topic: rq_read_track
        flow.readtrack.type: rtr
        flow.readtrack.cassandra.table: read_tracks
        flow.forwardtrack.name: forward_track
        flow.forwardtrack.topic: rq_forward_track
        flow.forwardtrack.type: frt
        flow.forwardtrack.cassandra.table: forward_tracks
        flow.conversion.name: conversion
        flow.conversion.topic: rq_conversion
        flow.conversion.type: con
        flow.conversion.cassandra.table: conversions
        flow.sendtransactional.name: send_transactional
        flow.sendtransactional.topic: rq_send_transactional
        flow.sendtransactional.type: str
        flow.sendtransactional.cassandra.table: send_transactionals
        flow.smsresponse.name: sms_response
        flow.smsresponse.topic: rq_sms_response
        flow.smsresponse.type: sms
        flow.smsresponse.cassandra.table: sms_responses
        flow.unsubscribe.name: unsubscribe
        flow.unsubscribe.topic: rq_unsubscribe
        flow.unsubscribe.type: uns
        flow.unsubscribe.cassandra.table: unsubscribes
        flow.skiptracking.name: skip_tracking
        flow.skiptracking.topic: rq_skip_tracking
        flow.skiptracking.type: skt
        flow.skiptracking.cassandra.table: skip_tracking
        flow.senttomta.name: sent_to_mta
        flow.senttomta.topic: rq_sent_to_mta
        flow.senttomta.type: stm
        flow.senttomta.cassandra.table: sent_to_mta
  mct-processor:
    package: 'mct-processor-flink'
    version: '1.0.49-1'
    configfiles:
      '/opt/mct-processor-flink/conf/config.yml':
        schema.registry.path: /schema_registry/schema_registry_master
        group.id: mapp-connect-processor
        topic.import.source: mct-processor
        topic.import.destination: ee-actions
        consul.url: hp13consul01
        consul.datacenter: emc
        flink.restart_on_failure: false
        processor.import.source.parallelism: 10
        processor.import.sink.parallelism: 10
        processor.import.event_distributor.parallelism: 5
        processor.import.bulk_processor.parallelism: 10
        processor.import.event_consolidator.parallelism: 10
        processor.import.event_transformator.parallelism: 20
        couchdb.url: http://hp13custint101.muc.domeus.com:5984/
        couchdb.name: integrations
        collocation.DEFAULT.name: EMC
        collocation.DEFAULT.url:
        collocation.DEFAULT.ignore.sysname: true
        collocation.DEFAULT.destination.topic: mct-cep-actions
        auto.offset.reset: earliest
        amazon.s3.enable: false
        amazon.s3.endpoint: http://opstcklab-112.muc.domeus.com/
        amazon.s3.bucket-name: mapp-connect
        amazon.s3.access-key: accessKey
        amazon.s3.secret-key: secretKey
        amazon.s3.region: region
  dmp-events:
    package: 'dmp-events-flink'
    version: '0.0.16'
    configfiles:
      '/opt/dmp-events-flink/conf/config.yml':
        schema.registry.path: /schema_registry/schema_registry_master
        consul.url: hp13consul01
        consul.datacenter: emc
        group.id: dmp-events-flink-emc
        dmpevents.source.parallelism: 2
        kafka.eventengine.sink.parallelism: 2
        kafka.eventengine.action.sink_parallelism: 2
        topic.dmpevents.source: dmp-real-time-events
        topic.eventengine.destination: ee-events
        topic.eventengine.action.destination: ee-actions
        checkpointing.interval: "%{hiera('flink::applications::defaults.checkpointing_interval')}"
        checkpointing.pause: 180000
        topic.dmp.response.event.destination: dmpresponse
  flink-phone-hbase:
    package: 'speedlayer-flink-phone-hbase'
    version: '2.1.2-1'
    configfiles:
      '/opt/speedlayer-flink-phone-hbase/conf/config.yml':
        checkpointing.interval: 2000
        checkpointing.mode: EXACTLY_ONCE
        checkpointing.pause: 0
        checkpointing.timeout: 1200000
        flink.time.window.ms: 1000
        flink.source.parallelism: 10
        flink.process.parallelism: 10
        flink.sink.parallelism: 10
        auto.offset.reset: 'earliest'
        hbase.zookeeper.znode.parent: "%{hiera('flink::applications::defaults.hbase_znode')}"
        hbase.table.name: phonedata-0
  flink-product-catalog:
    package: 'speedlayer-flink-product-catalog'
    version: '2.1.10-1'
    configfiles:
      '/opt/speedlayer-flink-product-catalog/conf/config.yml':
        auto.offset.reset: 'earliest'
        checkpointing.interval: "%{hiera('flink::applications::defaults.checkpointing_interval')}"
        checkpointing.mode: "%{hiera('flink::applications::defaults.checkpointing_mode')}"
        checkpointing.pause: "%{hiera('flink::applications::defaults.checkpointing_pause')}"
        flink.time.window.ms: "%{hiera('flink::applications::defaults.flink_time_window_ms')}"
        flink.process.parallelism: 2
        flink.sink.parallelism: 2
        flink.source.parallelism: 2
        hbase.zookeeper.znode.parent: "%{hiera('flink::applications::defaults.hbase_znode')}"
        hbase.productcatalog.table.name: productcatalog-speed-0
        hbase.productcatalog.family.name: catalog
  flink-kafka-reloader:
    package: 'kafka-reloader'
    version: '0.0.34-1'
    configfiles:
      '/opt/kafka-reloader/conf/config.yml':
        flink.source.parallelism: 5
        flink.sink.parallelism: 2
        defaults.customerWhitelist: 0
        kafka.enabled: webtrekk, datastore
        kafka.webtrekk.servers: ingestion-kafka-wd-prod-01.nbg.webtrekk.com:9092,ingestion-kafka-wd-prod-02.nbg.webtrekk.com:9092,ingestion-kafka-wd-prod-03.nbg.webtrekk.com:9092,ingestion-kafka-wd-prod-04.nbg.webtrekk.com:9092,ingestion-kafka-wd-prod-05.nbg.webtrekk.com:9092
        kafka.webtrekk.group: flink_kafka_reloader_prod
        kafka.webtrekk.properties: |-
          ssl.truststore.location: /opt/webtrekk/webtrekk-SRV-DC1-CA.truststore \n \
          ssl.truststore.password: %{hiera('secrets::flink::kafka-reloader::webtrekk::truststore::password')} \n \
          ssl.truststore.type: jks \n \
          enable.idempotence: true \n \
          sasl.mechanism: SCRAM-SHA-256 \n \
            security.protocol: SASL_SSL \n \
            sasl.jaas.config: org.apache.kafka.common.security.scram.ScramLoginModule required username="MappEngageIngestion" password="%{hiera('secrets::flink::kafka-reloader::webtrekk::kafka::password')}";
        kafka.datastore.group: flink_kafka_reloader
        kafka.datastore.schemaRegistryPath: /schema_registry/schema_registry_master
        kafka.datastore.properties: |-
            auto.offset.reset: earliest
        flow.enabled: userresponse,metadata
        flow.metadata.source: datastore
        flow.metadata.source.topic: metadata
        flow.metadata.source.parallelism: 5
        flow.metadata.destinations: webtrekk:mi.metadata
        flow.metadata.destinations.parallelism: 2
        flow.metadata.useWhitelist: true
        flow.metadata.customerWhitelist: 25002
        flow.metadata.source.sourceClass: com.teradata.datastore.wire.avro.metadata.AMetadataEvent
        flow.metadata.source.customerIdExtractor: com.mapp.datastore.kafkareloader.flow.extractors.MetadataCustomerIdExtractor
        flow.userresponse.source: datastore
        flow.userresponse.source.topic: userresponse
        flow.userresponse.source.parallelism: 5
        flow.userresponse.destinations: webtrekk:mi.userresponses
        flow.userresponse.destinations.parallelism: 2
        flow.userresponse.useWhitelist: true
        flow.userresponse.customerWhitelist: 25002
        flow.userresponse.source.customerIdExtractor: com.mapp.datastore.kafkareloader.flow.extractors.UserResponseCustomerIdExtractor
        flow.userresponse.source.sourceClass: com.teradata.datastore.wire.avro.UserResponseEvent
  webtrekk-segment-flink:
    package: 'webtrekk-segment-flink'
    version: '0.0.20'
    configfiles:
      '/opt/webtrekk-segment-flink/conf/config.yml':
        debug: true
        user.write.service.path: /services/userevent
        user.write.scheme: zk
        webtrekk.segment.source.parallelism: 4
        webtrekk.segment.extract.parallelism: 4
        datastore.sink.parallelism: 4
        checkpoiting.interval: 10000
        checkpointing.pause: 180000
        consul.url: hp13consul01
        consul.datacenter: emc
        colocation.whitelist: ts,p10
        socket.timeout: 5000
        connection.timeout: 5000
        topic.webtrekk.segment.source: mi.segments
        schema.registry.list: https://warp-schema-registry-prod-01.nbg.webtrekk.com:8080,https://warp-schema-registry-prod-02.nbg.webtrekk.com:8080
        kafka.webtrekk.servers: public-kafka-wd-prod-01.nbg.webtrekk.com:9092,public-kafka-wd-prod-02.nbg.webtrekk.com:9092,public-kafka-wd-prod-03.nbg.webtrekk.com:9092
        kafka.webtrekk.group: MappSegmentsConsumerEmc
        kafka.webtrekk.properties: |-
          ssl.truststore.location: /opt/webtrekk/webtrekk-SRV-DC1-CA.truststore \n \
          ssl.truststore.password: %{hiera('secrets::flink::webtrekk-segment::truststore::password')} \n \
          ssl.truststore.type: jks \n \
          sasl.mechanism: SCRAM-SHA-256 \n \
          security.protocol: SASL_SSL \n \
          sasl.jaas.config: org.apache.kafka.common.security.scram.ScramLoginModule required username="MappSegmentsConsumer" password="%{hiera('secrets::flink::webtrekk-segment::sasl::password')}";

# flink manager configuration
flink::manager::apps:
  flink_elasticsearch-user:
    defaults:
      disabled: 'Flink 1.9.2 test, use dsstreamm1040'
    prime:
      disabled: 'Flink 1.9.2 test, use dsstreamm1040'
    fast:
      disabled: 'Flink 1.9.2 test, use dsstreamm1040'
    reindex:
      disabled: 'Flink 1.9.2 test, use dsstreamm1040'
  flink_event-engine:
    defaults:
      disabled: 'Flink 1.9.2 test, use dsstreamm1040'
  flink_hbase:
    defaults:
      disabled: 'Flink 1.9.2 test, use dsstreamm1040'
  flink_hbase-mobileresponses:
    defaults:
      disabled: 'Flink 1.9.2 test, use dsstreamm1040'
  flink_hbase-statistics:
    defaults:
      yarn_session_tm_slots: 2
    regular:
      yarn_session_tm_memory: 6144
      flink_run_command: '/opt/speedlayer-flink-statistics/speedlayer-flink-statistics-*-fat.jar --config /opt/speedlayer-flink-statistics/conf/config.yml --time.window.marker 5000 --time.window.stats 10000 --flink.process.stats.recovery.enabled false'
    recovery:
      yarn_session_tm_memory: 4096
      flink_run_command: '/opt/speedlayer-flink-statistics/speedlayer-flink-statistics-*-fat.jar --config /opt/speedlayer-flink-statistics/conf/config-recovery.yml --time.window.marker 5000 --time.window.stats 10000 --flink.process.stats.recovery.enabled true'
  flink_hbase-userresponse:
    defaults:
      disabled: 'Flink 1.9.2 test, use dsstreamm1040'
  flink_interaction-planner:
    defaults:
      disabled: 'Flink 1.9.2 test, use dsstreamm1040'
  flink_locking-injection:
    defaults:
      disabled: 'Flink 1.9.2 test, use dsstreamm1040'
  flink_rq_writer:
    defaults:
      yarn_session_tm_memory: 2048
      yarn_session_tm_slots: 4
      flink_run_command: '/opt/response-queue-writer-flink/response-queue-writer-flink-*-fat.jar --config /opt/response-queue-writer-flink/conf/config.yml'
  flink_mct_processor:
    defaults:
      disabled: 'Flink 1.9.2 test, use dsstreamm1040'
  flink_relateddata:
    defaults:
      disabled: 'Flink 1.9.2 test, use dsstreamm1040'
    hbase:
      disabled: 'Flink 1.9.2 test, use dsstreamm1040'
    hbase-locking:
      disabled: 'Flink 1.9.2 test, use dsstreamm1040'
    hbase-tmp:
      disabled: 'Flink 1.9.2 test, use dsstreamm1040'
    elastic:
      disabled: 'Flink 1.9.2 test, use dsstreamm1040'
  flink_dmp:
    defaults:
      disabled: 'Flink 1.9.2 test, use dsstreamm1040'
  flink_phone-hbase:
    defaults:
      disabled: 'Flink 1.9.2 test, use dsstreamm1040'
  flink_kafka-reloader:
    defaults:
      disabled: 'Flink 1.9.2 test, use dsstreamm1040'
  flink_webtrekk-segment:
    defaults:
      disabled: 'Flink 1.9.2 test, use dsstreamm1040'
  flink_hbase-productcatalog:
    defaults:
      disabled: "Flink 1.9.2 tests, use dsstreamm140"
